<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Probing the Origins of Reasoning Performance | Algoverse AI Research</title>
    <meta name="description" content="Representational quality for mathematical problem-solving in RL vs SFT finetuned models.">
    <link rel="stylesheet" href="style.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
</head>
<body>
    <header class="header">
        <h1>Probing the Origins of Reasoning Performance: Representational Quality for Mathematical Problem-Solving in RL vs SFT Finetuned Models</h1>

        <div class="authors">
            <div class="author-list">
                <div class="author-item">
                    <div class="author-name">Antyabha Rahman<sup>†</sup></div>
                    <div class="author-affiliation">University of New South Wales</div>
                </div>
                <div class="author-item">
                    <div class="author-name">Akshaj Gurugubelli<sup>†</sup></div>
                    <div class="author-affiliation">Algoverse AI Research</div>
                </div>
                <div class="author-item">
                    <div class="author-name">Omar Ankit<sup>†</sup></div>
                    <div class="author-affiliation">University of Waterloo</div>
                </div>
                <div class="author-item">
                    <div class="author-name">Kevin Zhu<sup>†</sup></div>
                    <div class="author-affiliation">Algoverse AI Research</div>
                </div>
                <div class="author-item">
                    <div class="author-name">Aishwarya Balwani<sup>†‡</sup></div>
                    <div class="author-affiliation">St. Jude Children's Research Hospital</div>
                </div>
            </div>
            <div class="footnote">
                <sup>†</sup>Work conducted with Algoverse AI Research<br>
                <sup>‡</sup>Corresponding author. Email: aishwarya.balwani@stjude.org
            </div>
        </div>

        <nav class="nav-bar">
            <a href="https://github.com/oankit/-rl-sft-reasoning/" class="nav-button">
                <svg viewBox="0 0 16 16" xmlns="http://www.w3.org/2000/svg">
                    <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"></path>
                </svg>
                GitHub
            </a>
            <a href="https://openreview.net/forum?id=6bdhxhvBLd&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DAAAI.org%2F2026%2FWorkshop%2FXAI4Science%2FAuthors%23your-submissions)" class="nav-button">
                <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                    <path d="M14 2H6C4.9 2 4 2.9 4 4v16c0 1.1.9 2 2 2h12c1.1 0 2-.9 2-2V8l-6-6zM6 20V4h7v5h5v11H6z"></path>
                </svg>
                Paper
            </a>
            <a href="https://algoverseairesearch.org/" class="nav-button">
                Algoverse AI
            </a>
        </nav>
    </header>

    <div class="figure-section">
        <img src="images/slides.png" alt="Experimental Setup and Results">
    </div>

    <div class="container">
        <h2 class="abstract-title">Abstract</h2>
        <div class="content">
            <p>
                Large reasoning models trained via reinforcement learning (RL) have been increasingly shown to outperform their supervised fine-tuned (SFT) counterparts on mathematical reasoning tasks; yet, the mechanistic basis for this advantage remains unclear. We therefore ask: what internal representational differences enable RL models’ superior performance? Our work presents two converging lines of evidence. First, linear probes trained on layer-wise hidden states reveal that RL models tend to achieve higher accuracy in predicting answer correctness compared to SFT models, indicating more linearly separable and structured representations. Second, mean ablation studies show that RL models develop a hierarchical architecture where deeper layers become progressively more critical, whereas SFT models distribute importance uniformly across layers. Together, these findings demonstrate that RL training fundamentally restructures how models represent and process reasoning problems. Finally, we analyze token-count variability under repeated sampling across problems to assess adaptive compute allocation. While we observe higher variability in some RL-tuned models than in their SFT counterparts, we see strong consistency in others, suggesting that token allocation may depend more on the overall training pipeline than on RL versus SFT alone. We believe this token-allocation variability reveals the spread of plausible on-policy reasoning, highlighting which models exhibit stable policies versus those that are under-determined, potentially non-identifiable solution behaviour.
            </p>
        </div>
    </div>

    <!-- Citation -->
        <!-- <section id="citation">
            <h2>Citation</h2>
            <p>If you find this work useful, please cite our paper:</p>
            <div class="citation-box">
                <pre><code>@article{rahman2025reasoning,
  title={Probing the Origins of Reasoning Performance: Representational Quality for Mathematical Problem-Solving in RL vs SFT Finetuned Models},
  author={Rahman, Antyabha and Gurugubelli, Akshaj and Ankit, Omar and Zhu, Kevin and Balwani, Aishwarya},
  journal={arXiv preprint},
  year={2025}
}</code></pre>
            </div>
        </section> -->

    <footer>
        <p>&copy; 2025 Algoverse AI Research. All rights reserved.</p>
    </footer>
</body>
</html>

