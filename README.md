# Probing the Origins of Reasoning Performance

Representational Quality for Mathematical Problem-Solving in RL vs SFT Finetuned Models

## Authors

* Antyabha Rahman (University of New South Wales)
* Akshaj Gurugubelli (Algoverse AI Research)
* Omar Ankit (University of Waterloo)
* Kevin Zhu (Algoverse AI Research)
* **Aishwarya Balwani** (St. Jude Children's Research Hospital) - Corresponding Author

## Abstract

Large reasoning models trained via reinforcement learning (RL) substantially outperform their supervised counterparts on tasks requiring logic and mathematical reasoning, yet the mechanistic basis for these improvements remains unclear. We investigate this phenomenon through an integrated behavioral-mechanistic analysis of mathematical reasoning, asking: what internal differences enable RL models' superior performance?

## Website

Visit our project website: [https://oankit.github.io/-rl-sft-reasoning/](https://oankit.github.io/-rl-sft-reasoning/)

## Citation

```bibtex
@article{rahman2025reasoning,
  title={Probing the Origins of Reasoning Performance: Representational Quality for Mathematical Problem-Solving in RL vs SFT Finetuned Models},
  author={Rahman, Antyabha and Gurugubelli, Akshaj and Ankit, Omar and Zhu, Kevin and Balwani, Aishwarya},
  journal={arXiv preprint},
  year={2025}
}
```

## Contact

For questions, please contact: aishwarya.balwani@stjude.org

## Affiliation

Work conducted with Algoverse AI Research

---

Â© 2025 Algoverse AI Research. All rights reserved.

